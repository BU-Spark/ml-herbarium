{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3144f164-f238-4221-ac2c-830deaf6c94c",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a7feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from transformers import (TrOCRProcessor, \n",
    "                        VisionEncoderDecoderModel,)\n",
    "\n",
    "# add parent directory to path so that we can import our python scripts from all subdirectories\n",
    "cwd_prefix = \"/projectnb/sparkgrp/ml-herbarium-grp/summer2023/kabilanm/ml-herbarium/trocr/evaluation-dataset/handwritten-typed-text-classification/\"\n",
    "import sys\n",
    "sys.path.append(cwd_prefix)\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6fa737-6506-4f0c-94b3-1a9dbdfeedbe",
   "metadata": {},
   "source": [
    "## Initialize TrOCR Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228bb8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and processor\n",
    "# processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "# model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "cache_dir = cwd_prefix+\"model/\"\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-stage1', cache_dir=cache_dir)\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-stage1', cache_dir=cache_dir)\n",
    "\n",
    "# Freeze TrOCR layers (we will not train the TrOCR model)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364bd61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518ef62-2737-4265-a57f-f796fa2803e6",
   "metadata": {},
   "source": [
    "## Define Classifier (decoder for the TrOCR encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bcaf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  (10): Linear(in_features=294912, out_features=512, bias=True)\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Dropout(p=0.2, inplace=False)\n",
       "  (15): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (16): ReLU(inplace=True)\n",
       "  (17): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our  (we will train the classifier)\n",
    "classifier = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, 16, kernel_size=1, stride=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(16, 32, kernel_size=1, stride=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(32, 32, kernel_size=1, stride=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32 * (577 // 8) * (1024 // 8), 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.003)\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349078db-01e8-4a50-8d86-a65924be7465",
   "metadata": {},
   "source": [
    "## Initialize Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64821e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3607b22-243c-49ce-8f53-224550b9aeae",
   "metadata": {},
   "source": [
    "## Load and Split Dataset\n",
    "\n",
    "> **Note: TrOCRPreprocessor (custom data loader) and TrOCRProcessor (from hugging face transformers) are different classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa82e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset (since we don't have a train and validation split originally.\n",
    "# we will generate a split in the next step)\n",
    "dataset_path = cwd_prefix+\"data/all_preprocessed_data/\"\n",
    "\n",
    "# a wrapper for the custom data loader which applies TrOCRProcessor transformations\n",
    "dataset = TrOCRPreprocessor(dataset_path, processor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c5fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357104, 89276)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the split sizes\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create the DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5b15d-d566-4252-9acc-a6c207e59a90",
   "metadata": {},
   "source": [
    "## Parallelize Model if Multiple GPUs are Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d6f62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (12): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (13): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (14): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (15): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (16): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (17): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (18): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (19): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (20): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (21): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (22): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (23): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TrOCRForCausalLM(\n",
       "    (model): TrOCRDecoderWrapper(\n",
       "      (decoder): TrOCRDecoder(\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): TrOCRSinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there are multiple GPUs available, wrap the model with nn.DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, list(range(torch.cuda.device_count())))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeff9c5-2e5e-425d-912d-9193bb563a77",
   "metadata": {},
   "source": [
    "## Extract Features and Store Tensors\n",
    "\n",
    "This loop is to extract image representation (using the TrOCR encoder) and store the tensors.\n",
    "This was performed as part of the training loop. We have stored the TrOCR encoder's output as tensors so that we don't use the encoder in every epoch as it is a time consuming step. The encoding is done once and in the next step we use the stored tensors to train the classifier for multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5a8a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11160/11160 [4:59:46<00:00,  1.61s/it] \n",
      "100%|| 2790/2790 [1:15:25<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 1\n",
    "\n",
    "# # (this step is one-time as we are not training the TrOCR model)\n",
    "# for epoch in range(num_epochs):\n",
    "    \n",
    "#     with tqdm(enumerate(train_loader), total=math.ceil(train_size/batch_size)) as pbar:\n",
    "        \n",
    "#         for batch_idx, (pixel_values, labels) in pbar:\n",
    "#             pixel_values, labels = pixel_values.squeeze(1).to(device), labels.float().unsqueeze(1).to(device)\n",
    "                        \n",
    "#             # The `encoder_outputs` variable will contain the intermediate output \n",
    "#             # of the vision transformer part of the TrOCR model\n",
    "#             encoder_outputs = model.module.encoder(pixel_values)\n",
    "\n",
    "#             # This is the image representation\n",
    "#             image_representation = encoder_outputs.last_hidden_state\n",
    "#             # print(image_representation.shape)\n",
    "#             # image_representation = image_representation.mean(dim=1)  # shape will now be [32, 1, 1024, ]\n",
    "#             torch.save(image_representation.cpu(), f'tensors/train/train_image_representation_{epoch}_{batch_idx}.pt')\n",
    "#             torch.save(labels.cpu(), f'{cwd_prefix}tensors/train/labels_{epoch}_{batch_idx}.pt')\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         with tqdm(enumerate(val_loader), total=math.ceil(val_size/batch_size)) as pbar:\n",
    "\n",
    "#             for batch_idx, (pixel_values, labels) in pbar:\n",
    "#                 pixel_values, labels = pixel_values.squeeze(1).to(device), labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "#                 # The `encoder_outputs` variable will contain the intermediate output \n",
    "#                 # of the vision transformer part of the TrOCR model\n",
    "#                 encoder_outputs = model.module.encoder(pixel_values)\n",
    "\n",
    "#                 # This is the image representation\n",
    "#                 image_representation = encoder_outputs.last_hidden_state\n",
    "#                 # image_representation = image_representation.mean(dim=1)  # shape will now be [32, 768]\n",
    "#                 torch.save(image_representation.cpu(), f'tensors/valid/val_image_representation_{epoch}_{batch_idx}.pt')\n",
    "#                 torch.save(labels.cpu(), f'{cwd_prefix}tensors/valid/labels_{epoch}_{batch_idx}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3e454-31c4-4184-91f0-557fd7b90328",
   "metadata": {},
   "source": [
    "## TensorBoard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b587cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n",
      "/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py:175: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if height != self.image_size[0] or width != self.image_size[1]:\n"
     ]
    }
   ],
   "source": [
    "# TensorBoard setup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "writer = SummaryWriter(cwd_prefix+\"logs/trocr_encoder_w_classifier/\") # this will create a folder if there isn't one\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images, labels = images.squeeze(1).to(device), labels.to(device)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image(\"Sample training images\", img_grid)\n",
    "\n",
    "\n",
    "class ModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        # Convert the dictionary output to a tuple.\n",
    "        return tuple(output.values())\n",
    "\n",
    "# Visualize the classifier we created\n",
    "writer.add_graph(ModelWrapper(model.encoder), images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09f179-9ebb-43cd-96b5-9dacf7f0153e",
   "metadata": {},
   "source": [
    "## Load Tensors stored in the previous step (for training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b1a7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_directory = cwd_prefix+'tensors/train'\n",
    "train_dataset = TensorDataset(train_tensor_directory)\n",
    "train_loader_tensor = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "val_tensor_directory = cwd_prefix+'tensors/valid'\n",
    "val_dataset = TensorDataset(val_tensor_directory)\n",
    "val_loader_tensor = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d1f2d-dcc9-4936-adc6-d95d655f7049",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f87da-81fa-4878-9c5e-d05273b7c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "patience = 5\n",
    "\n",
    "classifier = torch.nn.DataParallel(classifier, [0]) # list(range(torch.cuda.device_count()))\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "writer = SummaryWriter(cwd_prefix+\"logs/trocr_encoder_w_classifier_exp_2/\")\n",
    "\n",
    "# Training loop\n",
    "classifier.train()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    val_correct = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    val_loss = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    with tqdm(enumerate(train_loader_tensor), total=math.ceil(train_size/batch_size)) as pbar:\n",
    "        \n",
    "        for batch_idx, (image_representation, labels) in pbar:\n",
    "            \n",
    "            image_representation = image_representation.squeeze(0).unsqueeze(1)\n",
    "            labels = labels.float().squeeze(0)\n",
    "            image_representation, labels = image_representation.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Pass the image features through the classifier\n",
    "            classifier_output = classifier(image_representation)\n",
    "            loss = loss_function(classifier_output, labels)\n",
    "            \n",
    "            predictions = torch.round(torch.sigmoid(classifier_output))\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    \n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(enumerate(val_loader_tensor), total=math.ceil(val_size/batch_size)) as pbar:\n",
    "\n",
    "            for batch_idx, (image_representation, labels) in pbar:\n",
    "                \n",
    "                image_representation = image_representation.squeeze(0).unsqueeze(1)\n",
    "                labels = labels.float().squeeze(0)\n",
    "                image_representation, labels = image_representation.to(device), labels.to(device)\n",
    "\n",
    "                # Pass the image features through the classifier\n",
    "                classifier_output = classifier(image_representation)\n",
    "                loss = loss_function(classifier_output, labels)\n",
    "\n",
    "                predictions = torch.round(torch.sigmoid(classifier_output))\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    # Calculate average loss and accuracy\n",
    "    train_loss /= train_size\n",
    "    train_accuracy = train_correct / train_size\n",
    "\n",
    "    val_loss /= val_size\n",
    "    val_accuracy = val_correct / val_size\n",
    "    \n",
    "    writer.add_scalars(\"Loss tracking\", {\"train_loss\": train_loss, \"val_loss\": val_loss}, epoch+1)\n",
    "    writer.add_scalars(\"Accuracy tracking\", {\"train_accuracy\": train_accuracy, \"val_accuracy\": val_accuracy}, epoch+1)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], \\n'\n",
    "        f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \\n'\n",
    "        f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f} \\n'\n",
    "        )\n",
    "    \n",
    "    # Save the best model based on validation loss and early stopping\n",
    "    if val_loss <= best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        # Save the model\n",
    "        print(\"Saving model...\")\n",
    "        torch.save(classifier.state_dict(), cwd_prefix+'model/TrOCR_L_enc_feature_extraction_w_classifier_retrained.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        # Check if the counter reaches the patience limit\n",
    "        if counter >= patience:\n",
    "            print('Early stopping triggered...')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3b537-8bfa-4fe5-a420-52392fb7cc68",
   "metadata": {},
   "source": [
    "## Load Trained Model (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ca5762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=294912, out_features=512, bias=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Dropout(p=0.2, inplace=False)\n",
       "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier = classifier\n",
    "\n",
    "test_classifier.load_state_dict(torch.load(\"model/TrOCR_L_enc_feature_extraction_w_classifier_retrained.pth\"))\n",
    "test_classifier.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9daff9-c890-40c7-9c1f-f36f0858b67e",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be474cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test dataset\n",
    "test_data_path = cwd_prefix+\"data/test_data/\"\n",
    "test_dataset = TrOCRPreprocessor(test_data_path, processor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "test_size = len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a02105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:05<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Testing loop\n",
    "test_classifier.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(enumerate(test_loader), total=math.ceil(test_size/batch_size)) as pbar:\n",
    "\n",
    "        for batch_idx, (pixel_values, labels) in pbar:\n",
    "            pixel_values, labels = pixel_values.squeeze(1).to(device), labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            # The `encoder_outputs` variable will contain the intermediate output \n",
    "            # of the vision transformer part of the TrOCR model\n",
    "            encoder_outputs = model.encoder(pixel_values)\n",
    "\n",
    "            # This is the image representation\n",
    "            image_representation = encoder_outputs.last_hidden_state\n",
    "\n",
    "            # Pass the image features through the classifier\n",
    "            classifier_output = test_classifier(image_representation.unsqueeze(1))\n",
    "            loss = loss_function(classifier_output, labels)\n",
    "\n",
    "            predictions = torch.round(torch.sigmoid(classifier_output)) # .squeeze(1)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_correct += (predictions == labels).sum().item()\n",
    "            \n",
    "            y_true.extend(labels) # Save Truth\n",
    "            y_pred.extend(predictions) # Save Prediction\n",
    "\n",
    "\n",
    "# Compute F1-scores (we need to move the these tensors to CPU to compute F1-scores)\n",
    "y_true_cpu = [tensor.cpu().detach().numpy() for tensor in y_true]\n",
    "y_pred_cpu = [tensor.cpu().detach().numpy() for tensor in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ab734-dbcd-43df-8ad5-34cb8e426d6f",
   "metadata": {},
   "source": [
    "## Compute Accuracy and F1-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bafda0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705882352941176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = test_correct/test_size\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40fada16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285713"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1 = f1_score(y_true_cpu, y_pred_cpu)\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62414df5",
   "metadata": {},
   "source": [
    "## Exploring the TrOCR model and preprocessor (please ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecc9b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.weight', 'encoder.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "550a7803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ii'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image from the IAM dataset\n",
    "# url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "image = Image.open(\"data/all_preprocessed_data/typed/FUNSD0000971160-10.jpg\").convert(\"RGB\")\n",
    "# image = Image.open(\"data/all_preprocessed_data/typed/syntheticfile-9_crops-000152.jpg\").convert(\"RGB\")\n",
    "\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3af6594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=384x384>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_image = transforms.ToPILImage()(pixel_values[0])\n",
    "temp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdf16af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2, 4132,    2]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de3b8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `encoder_outputs` variable will contain the intermediate output \n",
    "# of the vision transformer part of the TrOCR model\n",
    "encoder_outputs = model.encoder(pixel_values)\n",
    "\n",
    "# This is the image representation\n",
    "image_representation = encoder_outputs.last_hidden_state\n",
    "image_representation = image_representation.mean(dim=1)  # shape will now be [1, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d0341e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1725, -0.3867, -0.1286,  ...,  0.2052, -0.3625, -0.4994],\n",
       "        [-0.0924, -0.2957, -0.2853,  ...,  0.6164, -0.2388, -0.2822],\n",
       "        [ 0.1588, -0.3444, -0.2023,  ...,  0.5765, -0.0988, -0.1870],\n",
       "        ...,\n",
       "        [-0.0030, -0.6578,  0.2199,  ...,  0.3897, -0.0497, -0.4029],\n",
       "        [-0.2889, -0.2004,  0.1602,  ...,  0.5631, -0.2646, -0.0362],\n",
       "        [ 0.3208, -0.3533,  0.1339,  ...,  0.7275,  0.0027, -0.3574]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17431609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4add6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
